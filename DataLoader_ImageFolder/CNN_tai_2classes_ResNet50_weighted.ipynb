{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "gHUMwn6x5gs5",
    "outputId": "27047965-4a1c-4d9b-a5ec-c4b45079a9f0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subprocess as sub\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#print(\"PyTorch Version: \",torch.__version__)\n",
    "#print(\"Torchvision Version: \", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train and test paths\n",
    "train_directory = 'train_2types/'\n",
    "test_directory = 'test_2types/'\n",
    "\n",
    "# Define a set of transformations to augment the data\n",
    "image_transforms = { 'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=512, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Compose(\n",
       "     RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "     RandomRotation(degrees=[-15.0, 15.0], resample=False, expand=False)\n",
       "     RandomHorizontalFlip(p=0.5)\n",
       "     Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "     ToTensor()\n",
       "     Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       " ),\n",
       " 'test': Compose(\n",
       "     Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "     ToTensor()\n",
       "     Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       " )}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "bs = 64\n",
    " \n",
    "# Number of classes\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that facilitates the retrieval of location paths for the input.\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. \n",
    "    Extends torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from folders\n",
    "data = {'train': ImageFolderWithPaths(root=train_directory, transform=image_transforms['train']),\n",
    "         'test': ImageFolderWithPaths(root=test_directory, transform=image_transforms['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolderWithPaths\n",
       "     Number of datapoints: 1185\n",
       "     Root location: train_2types/\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(512, 512), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "                RandomRotation(degrees=[-15.0, 15.0], resample=False, expand=False)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            ),\n",
       " 'test': Dataset ImageFolderWithPaths\n",
       "     Number of datapoints: 482\n",
       "     Root location: test_2types/\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            )}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "dataset_sizes = {'train': len(data['train']), 'test': len(data['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 1185, 'test': 482}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training metadata\n",
    "df = pd.read_csv(\"metadata.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[(df[\"dataset\"] == \"train\") & (df[\"Tissue\"].isin([\"Skin\", \"Liver\"]))].reset_index(drop = True)\n",
    "#df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_test = df[(df[\"dataset\"] == \"test\") & (df[\"Tissue\"].isin([\"Skin\", \"Liver\"]))].reset_index(drop = True)\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training metadata\n",
    "#train_sample_meta = pd.read_csv(\"metadata.tsv\", sep = \"\\t\")\n",
    "#train_sample_meta = train_sample_meta[train_sample_meta[\"dataset\"] == \"train\"].sort_values(['Tissue', 'Tile']).reset_index(drop = True)\n",
    "train_sample_meta = df_train\n",
    "\n",
    "# Compute how many tiles per class\n",
    "class_sample_counts = pd.DataFrame(train_sample_meta[\"Tissue\"].value_counts().sort_index()).reset_index(drop=False)\n",
    "class_sample_counts.rename({\"index\": \"Tissue\", \"Tissue\":\"class_tiles\"}, axis = 1, inplace=True)\n",
    "train_sample_meta = train_sample_meta.merge(class_sample_counts, how=\"left\", on=\"Tissue\")\n",
    "\n",
    "# Add a weight vector for weighted random sampling for the training dataloader\n",
    "train_sample_meta[\"weight\"] = 1/train_sample_meta[\"class_tiles\"]\n",
    "\n",
    "weights = torch.Tensor(train_sample_meta[\"weight\"].values)\n",
    "weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, dataset_sizes[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': torch.utils.data.DataLoader(data['train'], batch_size=bs, shuffle=False, sampler=weighted_sampler),\n",
    "                'test': torch.utils.data.DataLoader(data['test'], batch_size=bs, shuffle=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders = {'train': torch.utils.data.DataLoader(data['train'], batch_size=bs, shuffle=False),\n",
    "#                'test': torch.utils.data.DataLoader(data['test'], batch_size=bs, shuffle=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Liver', 'Skin']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the train data and store the distribution of classes per batch\n",
    "label_mapper = dict(zip(range(0, len(data[\"train\"].classes)), data[\"train\"].classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Liver', 1: 'Skin'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained Inception Model\n",
    "#model = models.resnet152(pretrained=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform transfer learning by freezing the network, and changing the final FC layer from ResNet. Training will be first performed for this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final fully connected layer of ResNet Model for Transfer Learning.\n",
    "# Initialy, we will train only the new sequential layer.\n",
    "fc_inputs = model.fc.in_features\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(fc_inputs, 1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.4),\n",
    "    torch.nn.Linear(1000, num_classes), \n",
    "    torch.nn.LogSoftmax(dim=1)) # For using NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to be used on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer, loss Function, learning rate scheduler, and epochs\n",
    "loss_func = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, datasets, dataset_sizes, device, num_epochs=3):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    metrics = {\"train\": {\"loss\": [], \"acc\": []}, \n",
    "               \"test\" : {\"loss\": [], \"acc\": []}}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and test phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval() # Set to evaluation mode\n",
    "\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels, paths) in enumerate(datasets[phase]):\n",
    "\n",
    "                # push input to device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # forward\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            metrics[phase][\"loss\"].append(epoch_loss)\n",
    "            metrics[phase][\"acc\"].append(epoch_acc.cpu().numpy().item())\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model (training might fail if Colab assigns a GPU without enough memory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/6\n",
      "----------\n",
      "train Loss: 0.7822 Acc: 0.6321\n",
      "test Loss: 0.5583 Acc: 0.6846\n",
      "\n",
      "Epoch: 2/6\n",
      "----------\n",
      "train Loss: 0.2808 Acc: 0.8827\n",
      "test Loss: 0.4139 Acc: 0.7988\n",
      "\n",
      "Epoch: 3/6\n",
      "----------\n",
      "train Loss: 0.2348 Acc: 0.9139\n",
      "test Loss: 0.4337 Acc: 0.7863\n",
      "\n",
      "Epoch: 4/6\n",
      "----------\n",
      "train Loss: 0.2164 Acc: 0.9215\n",
      "test Loss: 0.4331 Acc: 0.7967\n",
      "\n",
      "Epoch: 5/6\n",
      "----------\n",
      "train Loss: 0.2217 Acc: 0.9232\n",
      "test Loss: 0.4302 Acc: 0.7925\n",
      "\n",
      "Epoch: 6/6\n",
      "----------\n",
      "train Loss: 0.2119 Acc: 0.9241\n",
      "test Loss: 0.4480 Acc: 0.7822\n",
      "\n",
      "Training complete in 29m 5s\n",
      "Best val Acc: 0.798755\n"
     ]
    }
   ],
   "source": [
    "model, metrics = train_model(model, loss_func, optimizer, lr_scheduler, \n",
    "                             dataloaders, dataset_sizes, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will unfreeze the rest of the network and train everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n",
      "----------\n",
      "train Loss: 0.3642 Acc: 0.8886\n",
      "test Loss: 2.2828 Acc: 0.5643\n",
      "\n",
      "Epoch: 2/10\n",
      "----------\n",
      "train Loss: 0.1138 Acc: 0.9662\n",
      "test Loss: 0.0052 Acc: 1.0000\n",
      "\n",
      "Epoch: 3/10\n",
      "----------\n",
      "train Loss: 0.0854 Acc: 0.9688\n",
      "test Loss: 0.0856 Acc: 0.9689\n",
      "\n",
      "Epoch: 4/10\n",
      "----------\n",
      "train Loss: 0.0561 Acc: 0.9831\n",
      "test Loss: 0.0405 Acc: 0.9834\n",
      "\n",
      "Epoch: 5/10\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9831\n",
      "test Loss: 0.0222 Acc: 0.9938\n",
      "\n",
      "Epoch: 6/10\n",
      "----------\n",
      "train Loss: 0.0296 Acc: 0.9916\n",
      "test Loss: 0.0075 Acc: 0.9979\n",
      "\n",
      "Epoch: 7/10\n",
      "----------\n",
      "train Loss: 0.0458 Acc: 0.9857\n",
      "test Loss: 0.0063 Acc: 1.0000\n",
      "\n",
      "Epoch: 8/10\n",
      "----------\n",
      "train Loss: 0.0406 Acc: 0.9890\n",
      "test Loss: 0.0090 Acc: 0.9979\n",
      "\n",
      "Epoch: 9/10\n",
      "----------\n",
      "train Loss: 0.0524 Acc: 0.9797\n",
      "test Loss: 0.0065 Acc: 1.0000\n",
      "\n",
      "Epoch: 10/10\n",
      "----------\n",
      "train Loss: 0.0404 Acc: 0.9882\n",
      "test Loss: 0.0118 Acc: 0.9979\n",
      "\n",
      "Training complete in 154m 16s\n",
      "Best val Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Un-freeze model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "loss_func = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "# Finetune the whole network\n",
    "epochs = 10\n",
    "model, metrics = train_model(model, loss_func, optimizer, lr_scheduler, \n",
    "                             dataloaders, dataset_sizes, device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(os.getcwd(), 'finetuned_resnet50_liver_skin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8886075949367088,\n",
       " 0.9662447257383966,\n",
       " 0.9687763713080169,\n",
       " 0.9831223628691983,\n",
       " 0.9831223628691983,\n",
       " 0.9915611814345991,\n",
       " 0.9856540084388186,\n",
       " 0.9890295358649789,\n",
       " 0.979746835443038,\n",
       " 0.9881856540084388]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"train\"][\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5643153526970954,\n",
       " 1.0,\n",
       " 0.9688796680497925,\n",
       " 0.983402489626556,\n",
       " 0.9937759336099585,\n",
       " 0.9979253112033195,\n",
       " 1.0,\n",
       " 0.9979253112033195,\n",
       " 1.0,\n",
       " 0.9979253112033195]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"test\"][\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36416611914770514,\n",
       " 0.1138209402152506,\n",
       " 0.08541401895666927,\n",
       " 0.05614423109257775,\n",
       " 0.048617595321015464,\n",
       " 0.02962666619804841,\n",
       " 0.04584976005277553,\n",
       " 0.04059626051472335,\n",
       " 0.05244237490721393,\n",
       " 0.04035237325583329]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"train\"][\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2827823468758357,\n",
       " 0.005231956317798617,\n",
       " 0.08556627942813383,\n",
       " 0.04047132941944471,\n",
       " 0.02218015972888136,\n",
       " 0.007540796326929356,\n",
       " 0.006270722209773494,\n",
       " 0.008955987189660676,\n",
       " 0.0065431132201584545,\n",
       " 0.011834957980825199]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[\"test\"][\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd1ed873610>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(7,4))\n",
    "ax[0].plot(metrics[\"train\"][\"loss\"], label='train-loss')\n",
    "ax[0].plot(metrics[\"test\"][\"loss\"], label='test-loss')\n",
    "\n",
    "ax[1].plot(metrics[\"train\"][\"acc\"], label='train-acc')\n",
    "ax[1].plot(metrics[\"test\"][\"acc\"], label='test-acc')\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=1000, out_features=2, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load trained model\n",
    "#model_trained = torch.load(os.path.join(os.getcwd(), 'finetuned_resnet50_liver_skin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Use_case_part_B_Training_a_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02bce44c8df24296a1eca7d652bbb2ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03401eab452541439aa249e7d30b6b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_114d0bbda7be44ccae9772529694d718",
      "placeholder": "",
      "style": "IPY_MODEL_05298e24ce91450aaf1d448d6e2f398e",
      "value": " 230M/230M [00:01&lt;00:00, 128MB/s]"
     }
    },
    "05298e24ce91450aaf1d448d6e2f398e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "114d0bbda7be44ccae9772529694d718": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "295e92e15e8d4971a8e0e4c16793a254": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3441bd59bbe94b5db9baeda4740b9097": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_adbfd87f7a0347908b2d6de103f11732",
       "IPY_MODEL_03401eab452541439aa249e7d30b6b95"
      ],
      "layout": "IPY_MODEL_02bce44c8df24296a1eca7d652bbb2ab"
     }
    },
    "adbfd87f7a0347908b2d6de103f11732": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0385d39f9f642d68abf40e93d141686",
      "max": 241530880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_295e92e15e8d4971a8e0e4c16793a254",
      "value": 241530880
     }
    },
    "e0385d39f9f642d68abf40e93d141686": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
